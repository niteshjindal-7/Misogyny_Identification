{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e185735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nitesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2023-07-15 00:10:06.892138: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import transformers\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertModel, BertConfig, AutoModel, AdamW\n",
    "import natsort\n",
    "import os\n",
    "from PIL import Image \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9262d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of common strings 9986\n",
      "filtered_df shape (9986, 8)\n",
      "(9986, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>text</th>\n",
       "      <th>prefix_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-What are you doing? -you told me to satanize ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bedroom Kitchen Bathroom Bron memes storage</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WAKEUP EARLY FREELANCERS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WAITING FOR THE END OF THE COVID  imgflip.com</td>\n",
       "      <td>15002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>15003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMART WOMEN ARE AROUND  imgflip.com</td>\n",
       "      <td>15003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com</td>\n",
       "      <td>15004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COOKING FOR MY WIFE  imgflip.com</td>\n",
       "      <td>15005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...</td>\n",
       "      <td>15006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9986 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0         1.jpg           0        0           0                0         0   \n",
       "1         2.jpg           0        0           0                0         0   \n",
       "2         3.jpg           0        0           0                0         0   \n",
       "3         4.jpg           0        0           0                0         0   \n",
       "4         5.jpg           0        0           0                0         0   \n",
       "...         ...         ...      ...         ...              ...       ...   \n",
       "9981  15002.jpg           0        0           0                0         0   \n",
       "9982  15003.jpg           0        0           0                0         0   \n",
       "9983  15004.jpg           0        0           0                0         0   \n",
       "9984  15005.jpg           0        0           0                0         0   \n",
       "9985  15006.jpg           0        0           0                0         0   \n",
       "\n",
       "                                                   text  prefix_file_name  \n",
       "0                                         Milk Milk.zip                 1  \n",
       "1     -What are you doing? -you told me to satanize ...                 2  \n",
       "2     imgflip.com ME 1254 NEW BUGS AFTER CHANGES BUG...                 3  \n",
       "3           Bedroom Kitchen Bathroom Bron memes storage                 4  \n",
       "4                              WAKEUP EARLY FREELANCERS                 5  \n",
       "...                                                 ...               ...  \n",
       "9981      WAITING FOR THE END OF THE COVID  imgflip.com             15002  \n",
       "9982                SMART WOMEN ARE AROUND  imgflip.com             15003  \n",
       "9983      GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com             15004  \n",
       "9984                   COOKING FOR MY WIFE  imgflip.com             15005  \n",
       "9985  LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...             15006  \n",
       "\n",
       "[9986 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "train2 = pd.read_csv('training1.csv', delimiter='\\t')\n",
    "\n",
    "IDs = []  #set1\n",
    "images = []\n",
    "directory = 'TRAINING'   # directory where we have images \n",
    "filenames = natsort.natsorted(os.listdir(directory))  \n",
    "\n",
    "# get the ids from the images, where images are having three channels; omit images if channels != 3\n",
    "for i, filename in enumerate(filenames):\n",
    "#     print(i, filename)\n",
    "    if filename.endswith(\".jpg\"):\n",
    "#         ID = int(filename[:-4])\n",
    "        ID = filename\n",
    "        pathname = os.path.join(directory, filename)\n",
    "        im = Image.open(pathname)\n",
    "        im = im.resize((224, 224))  # Resize the image to (224, 224)\n",
    "        imnp = np.array(im)\n",
    "        if len(imnp.shape) != 3:\n",
    "#             print(\"This is 1 channel, so we omit it\", imnp.shape, filename)\n",
    "            continue\n",
    "        IDs.append(ID)\n",
    "        images.append(imnp)\n",
    "        \n",
    "\n",
    "        \n",
    "def get_common_strings(list1, list2):\n",
    "    return list(set(list1) & set(list2))\n",
    "\n",
    "# Example usage\n",
    "list1 = IDs\n",
    "list2 = list(train2.file_name)  #from the text file where we have text description \n",
    "common_strings = get_common_strings(list1, list2)\n",
    "print('len of common strings', len(common_strings))\n",
    "\n",
    "\n",
    "\n",
    "# Sort the dataframe with natural ordering of the IDs\n",
    "train2['prefix_file_name'] = train2['file_name'].str.extract('(\\d+)').astype(int)\n",
    "# Assuming 'df' is your DataFrame\n",
    "sorted_df = train2.sort_values(by='prefix_file_name', ascending=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "# print('sorted_df shape', sorted_df.shape)\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'common_strings' is the list of strings\n",
    "# Get the common string values in the column \n",
    "filtered_df = sorted_df[sorted_df['file_name'].isin(common_strings)].reset_index(drop=True)\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print('filtered_df shape', filtered_df.shape)\n",
    "\n",
    "train3 = filtered_df.copy()\n",
    "print(train3.shape)\n",
    "\n",
    "\n",
    "# # We are just doing classification so no filename is required for our task. \n",
    "# train.drop(['file_name'], axis=1, inplace=True)\n",
    "# train = train.iloc[:, [-1] + list(range(len(train.columns)-1))]\n",
    "train = train3.rename(columns={'Text Transcription': 'text'})\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74abb690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FACEBOOK SINGLES GROUPS BELIKE WHEN A NEW WOMA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO, IF YOU'RE A FEMINIST HOW CAN YOU EAT DAIRY?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHEN A CUTE GIRL LEFT YOUR MESSAGE ON SEEN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photographing something you want to show every...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEY BABE CAN YOU MAKE ME A SANDWICH? Hey babe ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>IT'S NOT YOUR FAULT You didn't design the dres...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>THINK ABOUT HOW MUCH BETTER HER SKIN IS BREATH...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>THE STEREOTYPES ARE TRUE F SHE DOES HAVE A TIG...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>DRAWS NAKED PICTURES OF BLACK WOMEN 00 0000 GE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>\"You work too much.\" Me: OOL I want to be rich...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  misogynous  shaming  \\\n",
       "0    FACEBOOK SINGLES GROUPS BELIKE WHEN A NEW WOMA...           0        0   \n",
       "1      SO, IF YOU'RE A FEMINIST HOW CAN YOU EAT DAIRY?           1        0   \n",
       "2           WHEN A CUTE GIRL LEFT YOUR MESSAGE ON SEEN           0        0   \n",
       "3    Photographing something you want to show every...           1        0   \n",
       "4    HEY BABE CAN YOU MAKE ME A SANDWICH? Hey babe ...           0        0   \n",
       "..                                                 ...         ...      ...   \n",
       "995  IT'S NOT YOUR FAULT You didn't design the dres...           1        0   \n",
       "996  THINK ABOUT HOW MUCH BETTER HER SKIN IS BREATH...           0        0   \n",
       "997  THE STEREOTYPES ARE TRUE F SHE DOES HAVE A TIG...           1        0   \n",
       "998  DRAWS NAKED PICTURES OF BLACK WOMEN 00 0000 GE...           0        0   \n",
       "999  \"You work too much.\" Me: OOL I want to be rich...           0        0   \n",
       "\n",
       "     stereotype  objectification  violence  \n",
       "0             0                0         0  \n",
       "1             1                1         0  \n",
       "2             0                0         0  \n",
       "3             1                1         0  \n",
       "4             0                0         0  \n",
       "..          ...              ...       ...  \n",
       "995           1                1         0  \n",
       "996           0                0         0  \n",
       "997           1                1         0  \n",
       "998           0                0         0  \n",
       "999           0                0         0  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv('Test.csv', delimiter='\\t')\n",
    "test_labels = pd.read_csv('test_labels.txt', \n",
    "                          delimiter='\\t',\n",
    "                         header=None)\n",
    "\n",
    "test_labels.columns = ['file_name', \n",
    "                      \"misogynous\",\n",
    "                       \"shaming\",\n",
    "                       \"stereotype\",\n",
    "                       \"objectification\",\n",
    "                       \"violence\"]\n",
    "\n",
    "test2 = pd.merge(test1, test_labels, on='file_name', how='inner')\n",
    "\n",
    "# train.drop(['file_name'], axis=1, inplace=True)\n",
    "test2.drop(['file_name'], axis=1, inplace=True)\n",
    "# train = train.iloc[:, [-1] + list(range(len(train.columns)-1))]\n",
    "\n",
    "\n",
    "# train = train.rename(columns={'Text Transcription': 'text'})\n",
    "test = test2.rename(columns={'Text Transcription': 'text'})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de11a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_classification_report(report, mod, exec_time):\n",
    "    lines = report.split('\\n')\n",
    "    data = lines[2:4] + lines[5:9]\n",
    "    data = [line.split() for line in data]\n",
    "    \n",
    "\n",
    "    acc = float(data[2][1])\n",
    "    m_prec = float(data[3][2])\n",
    "    m_recall = float(data[3][3])\n",
    "    m_f1 = float(data[3][4])\n",
    "    w_prec = float(data[4][2])\n",
    "    w_recall = float(data[4][3])\n",
    "    w_f1 = float(data[4][4])\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Model': [mod],\n",
    "        'Accuracy': [acc],\n",
    "        'M-Precision': [m_prec],\n",
    "        'M-Recall': [m_recall],\n",
    "        'M-F1-Score': [m_f1],\n",
    "        'W-Precision': [w_prec],\n",
    "        'W-Recall': [w_recall],\n",
    "        'W-F1-Score': [w_f1],\n",
    "        'Runtime': [exec_time]\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752ec3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''\n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)\n",
    "\n",
    "def cleanPunc(text): \n",
    "    '''function to clean the word of any punctuation or special characters'''\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',text)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(text):\n",
    "    alpha_sent = \"\"\n",
    "    for word in text.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = remove_space(text)\n",
    "    text = cleanPunc(text)\n",
    "    text = keepAlpha(text)\n",
    "    return text\n",
    "\n",
    "train['clean_text'] = train['text'].str.lower()\n",
    "train['clean_text'] = train['text'].apply(text_preprocessing_pipeline)\n",
    "test['clean_text'] = test['text'].apply(text_preprocessing_pipeline)\n",
    "train.head()\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        \n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "train['clean_text'] = train['clean_text'].apply(stemming)\n",
    "test['clean_text'] = test['clean_text'].apply(stemming)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(train['clean_text'])\n",
    "xtest_tfidf = tfidf_vectorizer.transform(test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea98359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.00857400894165039 seconds\n",
      "Execution time: 0.0047528743743896484 seconds\n",
      "Execution time: 0.004613637924194336 seconds\n",
      "Execution time: 0.004480123519897461 seconds\n",
      "Execution time: 0.004380702972412109 seconds\n",
      "Execution time: 0.00436854362487793 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>M-Precision</th>\n",
       "      <th>M-Recall</th>\n",
       "      <th>M-F1-Score</th>\n",
       "      <th>W-Precision</th>\n",
       "      <th>W-Recall</th>\n",
       "      <th>W-F1-Score</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.008574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.004753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.004480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  M-Precision  M-Recall  M-F1-Score  W-Precision  W-Recall  \\\n",
       "0    NB     0.590        0.602     0.590       0.578        0.602     0.590   \n",
       "0    NB     0.601        0.617     0.601       0.587        0.617     0.601   \n",
       "0    NB     0.592        0.607     0.592       0.577        0.607     0.592   \n",
       "0    NB     0.602        0.618     0.602       0.588        0.618     0.602   \n",
       "0    NB     0.594        0.607     0.594       0.581        0.607     0.594   \n",
       "0    NB     0.590        0.605     0.590       0.575        0.605     0.590   \n",
       "\n",
       "   W-F1-Score   Runtime  \n",
       "0       0.578  0.008574  \n",
       "0       0.587  0.004753  \n",
       "0       0.577  0.004614  \n",
       "0       0.588  0.004480  \n",
       "0       0.581  0.004381  \n",
       "0       0.575  0.004369  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Prepare the data\n",
    "X_train = xtrain_tfidf\n",
    "y_train = train['misogynous']\n",
    "\n",
    "\n",
    "X_test = xtest_tfidf\n",
    "y_test = test['misogynous']\n",
    "\n",
    "# np.random.seed(7)\n",
    "# bootstrap_iterations=5\n",
    "df=pd.DataFrame(columns=['Model', 'Accuracy', \n",
    "                       'M-Precision', 'M-Recall', \n",
    "                       'M-F1-Score', 'W-Precision',\n",
    "                       'W-Recall', 'W-F1-Score', 'Runtime'])\n",
    "\n",
    "# for _ in range(bootstrap_iterations):\n",
    "    \n",
    "for i in list([7,10,18,22,55,77]):\n",
    "    \n",
    "    random.seed(i)\n",
    "    np.random.seed(i)\n",
    "#     torch.manual_seed(i)\n",
    "#     tf.random.set_seed(i)\n",
    "    \n",
    "    start_time = time.time()\n",
    "        \n",
    "    # Perform bootstrap resampling on the training data\n",
    "    bootstrap_indices = np.random.choice(X_train.shape[0], size=X_train.shape[0], replace=True)\n",
    "    X_train_bootstrap = X_train[bootstrap_indices]\n",
    "    y_train_bootstrap = y_train[bootstrap_indices]\n",
    "\n",
    "    # Train a Naive Bayes classifier\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = nb.predict(X_test)\n",
    "    report = classification_report(list(y_test), list(y_pred), digits=3) \n",
    "#     print(report)\n",
    "    end_time = time.time()\n",
    "    execution_time1 = end_time - start_time\n",
    "\n",
    "    print(f\"Execution time: {execution_time1} seconds\")\n",
    "    model= 'NB'\n",
    "    df1 = export_classification_report(report, model,  execution_time1)\n",
    "#     print(df)\n",
    "    df = pd.concat([df, df1])\n",
    "display(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b00fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('1_classification_report_NB.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857b74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(\"classification_report.xlsx\") as writer:\n",
    "#     df.to_excel(writer, sheet_name=\"Sheet1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed65e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pandas as pd\n",
    "# # from openpyxl import load_workbook\n",
    "\n",
    "# # # Load the existing Excel file\n",
    "# # excel_file = 'classification_report.xlsx'\n",
    "# # existing_data = pd.read_excel(excel_file)\n",
    "\n",
    "# # # Append new dataframe rows\n",
    "# # new_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "\n",
    "# !pip install deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d57fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca10a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
